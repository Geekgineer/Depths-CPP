{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYAkd_SmyfJ6",
        "outputId": "baf34254-9977-4779-cb4b-562da17b96a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Depth-Anything-ONNX'...\n",
            "remote: Enumerating objects: 216, done.\u001b[K\n",
            "remote: Counting objects: 100% (216/216), done.\u001b[K\n",
            "remote: Compressing objects: 100% (166/166), done.\u001b[K\n",
            "remote: Total 216 (delta 72), reused 180 (delta 43), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (216/216), 6.95 MiB | 13.42 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/fabio-sim/Depth-Anything-ONNX.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Depth-Anything-ONNX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLKQ7MFnysRF",
        "outputId": "a7f97b83-8aa4-4379-f637-5253056cffb8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Depth-Anything-ONNX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxconverter_common onnxsim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "g_6rL6t2y335",
        "outputId": "b0e30029-1c1f-47b8-f2c6-5201fadd1941"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxconverter_common\n",
            "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting onnxsim\n",
            "  Downloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from onnxconverter_common) (1.26.4)\n",
            "Collecting onnx (from onnxconverter_common)\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxconverter_common) (24.2)\n",
            "Collecting protobuf==3.20.2 (from onnxconverter_common)\n",
            "  Downloading protobuf-3.20.2-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from onnxsim) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\n",
            "Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.2-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, onnx, onnxsim, onnxconverter_common\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.17.0 onnxconverter_common-1.14.0 onnxsim-0.4.36 protobuf-3.20.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "31eb70c0f4d04272809ebbc994735478"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1uP4pbiy46_",
        "outputId": "432fd30f-7ad9-422c-a8e6-265556b67a63"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.17.0)\n",
            "Collecting onnxruntime-gpu (from -r requirements.txt (line 3))\n",
            "  Downloading onnxruntime_gpu-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting onnxscript (from -r requirements.txt (line 4))\n",
            "  Downloading onnxscript-0.2.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting onnxslim (from -r requirements.txt (line 5))\n",
            "  Downloading onnxslim-0.1.48-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (4.11.0.86)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.67.1)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.15.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->-r requirements.txt (line 2)) (3.20.2)\n",
            "Collecting coloredlogs (from onnxruntime-gpu->-r requirements.txt (line 3))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu->-r requirements.txt (line 3)) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu->-r requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from onnxscript->-r requirements.txt (line 4)) (4.12.2)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.11/dist-packages (from onnxscript->-r requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 7)) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 7)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 7)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 7)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 7)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 7)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 7)) (3.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 8)) (11.1.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer->-r requirements.txt (line 10)) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->-r requirements.txt (line 10)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer->-r requirements.txt (line 10)) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer->-r requirements.txt (line 10)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer->-r requirements.txt (line 10)) (2.18.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu->-r requirements.txt (line 3))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 7)) (3.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->-r requirements.txt (line 10)) (0.1.2)\n",
            "Downloading onnxruntime_gpu-1.21.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.8/280.8 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxscript-0.2.2-py3-none-any.whl (694 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m694.9/694.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxslim-0.1.48-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.9/142.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, onnxslim, onnxscript, nvidia-cusparse-cu12, nvidia-cudnn-cu12, coloredlogs, onnxruntime-gpu, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-gpu-1.21.0 onnxscript-0.2.2 onnxslim-0.1.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python dynamo.py export --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbqGgOSO0VNr",
        "outputId": "19c0ed51-82e3-4980-fc2a-6b63be3f5797"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m                                                                                                    \u001b[0m\n",
            "\u001b[1m \u001b[0m\u001b[1;33mUsage: \u001b[0m\u001b[1mdynamo.py export [OPTIONS]\u001b[0m\u001b[1m                                                                 \u001b[0m\u001b[1m \u001b[0m\n",
            "\u001b[1m                                                                                                    \u001b[0m\n",
            " Export Depth-Anything V2 using TorchDynamo.                                                        \n",
            "                                                                                                    \n",
            "\u001b[2m╭─\u001b[0m\u001b[2m Options \u001b[0m\u001b[2m───────────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
            "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-encoder\u001b[0m                            \u001b[1;2;33m[\u001b[0m\u001b[1;33mvits\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mvitb\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mvitl\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mvitg\u001b[0m\u001b[1;2;33m]\u001b[0m  \u001b[2m[default: vitb]\u001b[0m                      \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-metric\u001b[0m                             \u001b[1;2;33m[\u001b[0m\u001b[1;33mindoor\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33moutdoor\u001b[0m\u001b[1;2;33m]\u001b[0m\u001b[1;33m     \u001b[0m  Export metric depth models.          \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m                                                             \u001b[2m[default: None]            \u001b[0m          \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-output\u001b[0m      \u001b[1;32m-o\u001b[0m                     \u001b[1;33mFILE                 \u001b[0m  Path to save exported model.         \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m                                                             \u001b[2m[default: None]             \u001b[0m         \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-format\u001b[0m      \u001b[1;32m-f\u001b[0m                     \u001b[1;2;33m[\u001b[0m\u001b[1;33monnx\u001b[0m\u001b[1;2;33m|\u001b[0m\u001b[1;33mpt2\u001b[0m\u001b[1;2;33m]\u001b[0m\u001b[1;33m           \u001b[0m  Export format. \u001b[2m[default: onnx]\u001b[0m       \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-batch\u001b[0m\u001b[1;36m-size\u001b[0m  \u001b[1;32m-b\u001b[0m                     \u001b[1;33mINTEGER RANGE [x>=0\u001b[0m\u001b[1;2;33m]\u001b[0m\u001b[1;33m \u001b[0m  Batch size of exported ONNX model.   \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m                                                             Set to 0 to mark as dynamic.         \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m                                                             \u001b[2m[default: 1]                        \u001b[0m \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-height\u001b[0m      \u001b[1;32m-h\u001b[0m                     \u001b[1;33mINTEGER RANGE [x>=0\u001b[0m\u001b[1;2;33m]\u001b[0m\u001b[1;33m \u001b[0m  Height of input image. Set to 0 to   \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m                                                             mark as dynamic.                     \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m                                                             \u001b[2m[default: 518]                      \u001b[0m \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-width\u001b[0m       \u001b[1;32m-w\u001b[0m                     \u001b[1;33mINTEGER RANGE [x>=0\u001b[0m\u001b[1;2;33m]\u001b[0m\u001b[1;33m \u001b[0m  Width of input image. Set to 0 to    \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m                                                             mark as dynamic.                     \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m                                                             \u001b[2m[default: 518]                      \u001b[0m \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-opset\u001b[0m                              \u001b[1;33mINTEGER RANGE [x<=17\u001b[0m\u001b[1;2;33m]\u001b[0m  ONNX opset version of exported       \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m                                                             model. Defaults to 17.               \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m                                                             \u001b[2m[default: 17]                       \u001b[0m \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-use\u001b[0m\u001b[1;36m-dynamo\u001b[0m      \u001b[1;35m-\u001b[0m\u001b[1;35m-no\u001b[0m\u001b[1;35m-use-dynamo\u001b[0m    \u001b[1;33m                     \u001b[0m  Use TorchDynamo (Beta) for ONNX      \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m                                                             export. Only supports static shapes  \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m                                                             and opset 18.                        \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m                                                             \u001b[2m[default: no-use-dynamo]            \u001b[0m \u001b[2m│\u001b[0m\n",
            "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-help\u001b[0m                               \u001b[1;33m                     \u001b[0m  Show this message and exit.          \u001b[2m│\u001b[0m\n",
            "\u001b[2m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python dynamo.py export --encoder vits --output weights/vits.onnx --opset 17"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFGY8GsRy83V",
        "outputId": "87571374-12ee-4156-dd50-bcb1852d1375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exporting to ONNX using legacy JIT tracer.\n",
            "/content/Depth-Anything-ONNX/depth_anything_v2/dinov2.py:204: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if npatch == N and w == h:  # Safe to ignore warning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python dynamo.py export --encoder vits --metric indoor --output weights/vits_metric_indoor.onnx --opset 17"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqcPpo9S4njz",
        "outputId": "bb83f20d-8486-4c33-d36e-201064769e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://huggingface.co/depth-anything/Depth-Anything-V2-Metric-Hypersim-Small/resolve/main/depth_anything_v2_metric_hypersim_vits.pth?download=true\" to /root/.cache/torch/hub/checkpoints/depth_anything_v2_metric_hypersim_vits.pth\n",
            "100% 94.6M/94.6M [00:00<00:00, 217MB/s]\n",
            "Exporting to ONNX using legacy JIT tracer.\n",
            "/content/Depth-Anything-ONNX/depth_anything_v2/dinov2.py:204: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if npatch == N and w == h:  # Safe to ignore warning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python dynamo.py export --encoder vits --metric outdoor --output weights/vits_metric_outdoor.onnx --opset 17"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvlJTkV95M_G",
        "outputId": "00cfd227-e284-4391-eba3-27c1c86130d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://huggingface.co/depth-anything/Depth-Anything-V2-Metric-VKITTI-Small/resolve/main/depth_anything_v2_metric_vkitti_vits.pth?download=true\" to /root/.cache/torch/hub/checkpoints/depth_anything_v2_metric_vkitti_vits.pth\n",
            "100% 94.6M/94.6M [00:02<00:00, 40.8MB/s]\n",
            "Exporting to ONNX using legacy JIT tracer.\n",
            "/content/Depth-Anything-ONNX/depth_anything_v2/dinov2.py:204: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if npatch == N and w == h:  # Safe to ignore warning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "import onnxruntime\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "from onnxconverter_common import float16\n",
        "from onnxsim import simplify\n",
        "\n",
        "# Paths\n",
        "model_fp32 = \"weights/vits_batch.onnx\"\n",
        "model_fp16 = \"weights/vits_fp16.onnx\"\n",
        "model_quint8 = \"weights/vits_quint8.onnx\"\n",
        "model_qint8_sim = \"weights/vits_qint8_sim.onnx\"\n",
        "model_sim = \"weights/vits_sim.onnx\"\n",
        "\n",
        "# model_fp32 = \"weights/vits_metric_indoor.onnx\"\n",
        "# model_fp16 = \"weights/vits_metric_indoor_fp16.onnx\"\n",
        "# model_qint8 = \"weights/vits_metric_indoor_qint8.onnx\"\n",
        "# model_qint8_sim = \"weights/vits_metric_indoor_qint8_sim.onnx\"\n",
        "# model_sim = \"weights/vits_metric_indoor_sim.onnx\"\n",
        "\n",
        "# model_fp32 = \"weights/vits_metric_outdoor.onnx\"\n",
        "# model_fp16 = \"weights/vits_metric_outdoor_fp16.onnx\"\n",
        "# model_qint8 = \"weights/vits_metric_outdoor_qint8.onnx\"\n",
        "# model_qint8_sim = \"weights/vits_metric_outdoor_qint8_sim.onnx\"\n",
        "# model_sim = \"weights/vits_metric_outdoor_sim.onnx\"\n",
        "\n",
        "\n",
        "# Load ONNX Model\n",
        "onnx_model = onnx.load(model_fp32)\n",
        "\n",
        "# 1. Convert to FP16\n",
        "print(f\"Converting {model_fp32} to FP16...\")\n",
        "onnx_fp16_model = float16.convert_float_to_float16(onnx_model)\n",
        "onnx.save(onnx_fp16_model, model_fp16)\n",
        "\n",
        "# 2. Quantize to INT8 (dynamic)\n",
        "print(f\"Quantizing {model_fp32} to INT8...\")\n",
        "quantize_dynamic(\n",
        "    model_input=model_fp32,\n",
        "    model_output=model_quint8,\n",
        "    weight_type=QuantType.QUInt8,\n",
        ")\n",
        "\n",
        "# 3. Simplify FP32 model\n",
        "print(f\"Simplifying {model_fp32}...\")\n",
        "onnx_model, check = simplify(onnx_model)\n",
        "onnx.save(onnx_model, model_sim)\n",
        "\n",
        "# 4. Simplify Quantized INT8 model\n",
        "print(f\"Simplifying {model_qint8}...\")\n",
        "onnx_model_int8 = onnx.load(model_qint8)\n",
        "onnx_model_int8, check = simplify(onnx_model_int8)\n",
        "onnx.save(onnx_model_int8, model_qint8_sim)\n",
        "\n",
        "print(\"All models generated successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWKbezrL5VtS",
        "outputId": "0120cf47-d828-4a65-e7c9-c29b78f9d379"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting weights/vits_batch.onnx to FP16...\n",
            "Quantizing weights/vits_batch.onnx to INT8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simplifying weights/vits_batch.onnx...\n",
            "Simplifying weights/vits_qint8.onnx...\n",
            "All models generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fiz9R-ps7ieH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}